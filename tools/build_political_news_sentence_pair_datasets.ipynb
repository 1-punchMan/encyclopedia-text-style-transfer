{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adaptive-timber",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zchen/miniconda3/envs/text_style_transfer/lib/python3.9/site-packages/requests/__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.8) or chardet (5.0.0)/charset_normalizer (2.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported \"\n"
     ]
    }
   ],
   "source": [
    "import json, os, re, random, string\n",
    "from tqdm import tqdm\n",
    "from ckiptagger import data_utils, construct_dictionary, WS, POS, NER\n",
    "from rank_bm25 import BM25Okapi\n",
    "from opencc import OpenCC\n",
    "cc_t2s = OpenCC('t2s')\n",
    "cc_s2t = OpenCC('s2t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "subject-cursor",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# path = \"/home/zchen/encyclopedia-text-style-transfer/tools/ckip/\"\n",
    "# data_utils.download_data_url(path)\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "# path = path + \"data\"\n",
    "# ws = WS(path, disable_cuda=False)\n",
    "# pos = POS(path, disable_cuda=False)\n",
    "# ner = NER(path, disable_cuda=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "monetary-interval",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(file):\n",
    "    with open(file, 'r', encoding=\"utf-8\") as f:\n",
    "        return f.read()\n",
    "        \n",
    "def save(file, string):\n",
    "    with open(file, 'w', encoding=\"utf-8\") as f:\n",
    "        f.write(string)\n",
    "        \n",
    "def load_json(file):\n",
    "    with open(file, 'r', encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def save_json(file, obj):\n",
    "    with open(file, 'w', encoding=\"utf-8\") as f:\n",
    "        json.dump(obj, f, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e56dd3c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def clean_ltn_news(news):\n",
    "    news = news.strip()\n",
    "    \n",
    "    # Remove 〔...〕 at the beginning.\n",
    "    m = re.match(r\"〔.*〕\", news)\n",
    "    if m:\n",
    "        end = m.end()\n",
    "        news = news[end:].strip()\n",
    "    \n",
    "    news = news.split('\\n')\n",
    "    \n",
    "    # Remove (...) at the end.\n",
    "    news[-1] = re.sub(r\"[(（].*[)）]\", \"\", news[-1]).strip()\n",
    "    \n",
    "    return '\\n'.join(news)\n",
    "\n",
    "def clean_cn_news(news):\n",
    "    news = news.strip()\n",
    "    \n",
    "    # Remove ...日电 at the beginning.\n",
    "    m = re.match(r\".*日电\", news)\n",
    "    if m:\n",
    "        end = m.end()\n",
    "        news = news[end:].strip()\n",
    "    \n",
    "    news = news.split('\\n')\n",
    "    \n",
    "    # Remove (...) at the beginning.\n",
    "    m = re.search(r\"[(（].*[)）]\", news[0])\n",
    "    if m:\n",
    "        end = m.end()\n",
    "        news[0] = news[0][end:].strip()\n",
    "    \n",
    "    # Remove (...) at the end.\n",
    "    news[-1] = re.sub(r\"[(（].*[)）]\", \"\", news[-1]).strip()\n",
    "        \n",
    "    return '\\n'.join(news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fresh-practice",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3849\n",
      "7496\n"
     ]
    }
   ],
   "source": [
    "file = \"/home/zchen/encyclopedia-text-style-transfer/data/political_news/raw/Chinanews_articles.json\"\n",
    "cn_arts = [{\"headline\": news[\"headline\"], \"text\": clean_cn_news(news[\"text\"])} for news in load_json(file)]\n",
    "print(len(cn_arts))\n",
    "\n",
    "files = [\n",
    "    \"/home/zchen/encyclopedia-text-style-transfer/data/political_news/raw/articles_3800k-3825k.json\",\n",
    "    \"/home/zchen/encyclopedia-text-style-transfer/data/political_news/raw/articles_3825k-3850k.json\",\n",
    "    \"/home/zchen/encyclopedia-text-style-transfer/data/political_news/raw/articles_3850k-3900k.json\"\n",
    "]\n",
    "tw_arts = []\n",
    "for file in files:\n",
    "    tw_arts += [{\"headline\": news[\"headline\"], \"text\": clean_ltn_news(news[\"text\"])} for news in load_json(file)]\n",
    "print(len(tw_arts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "explicit-cabin",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(line):\n",
    "    rule = re.compile(r\"[^a-zA-Z0-9\\u4e00-\\u9fa5]\")\n",
    "    line = rule.sub(' ',line)\n",
    "    return line\n",
    "\n",
    "def tokenize_arts(arts, file):\n",
    "    if os.path.exists(file):\n",
    "        return load(file).strip().split('\\n')\n",
    "    else:\n",
    "        tok_arts = []\n",
    "        for i, art in enumerate(tqdm(arts)):\n",
    "            art = cc_s2t.convert(art[\"headline\"] + '\\n' + art[\"text\"])\n",
    "            art = [sent for sent in art.split('\\n') if sent]\n",
    "            art_ = []\n",
    "            for sent in ws(art):\n",
    "                art_ += sent\n",
    "            tok_arts.append(remove_punctuation(' '.join(art_)))    # Saving space.\n",
    "        save(file, '\\n'.join(tok_arts))\n",
    "        return tok_arts\n",
    "\n",
    "def split_sent(arts):\n",
    "    \"\"\" For space saving purpose. \"\"\"\n",
    "    return [art.split() for art in arts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "coordinate-estonia",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1hr\n",
    "file = \"/home/zchen/encyclopedia-text-style-transfer/data/political_news/tok_cn_arts\"\n",
    "tok_cn_arts = tokenize_arts(cn_arts, file)\n",
    "assert len(tok_cn_arts) == len(cn_arts), (cn_arts, tok_cn_arts)\n",
    "\n",
    "file = \"/home/zchen/encyclopedia-text-style-transfer/data/political_news/tok_tw_arts\"\n",
    "tok_tw_arts = tokenize_arts(tw_arts, file)\n",
    "assert len(tok_tw_arts) == len(tw_arts), (tw_arts, tok_tw_arts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "confident-falls",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_art_pairs(src_arts, tok_src_arts, targ_arts, tok_targ_arts, file):\n",
    "    if os.path.exists(file):\n",
    "        return load_json(file)\n",
    "    else:\n",
    "        bm25 = BM25Okapi(split_sent(tok_targ_arts))\n",
    "        \n",
    "        # 30min\n",
    "        iterable = zip(src_arts, split_sent(tok_src_arts))\n",
    "        art_pairs = [\n",
    "            (art, bm25.get_top_n(tok_art, list(range(len(targ_arts))), n=5))\n",
    "            for art, tok_art in tqdm(list(iterable))\n",
    "        ]\n",
    "        save_json(file, art_pairs)\n",
    "        return art_pairs\n",
    "    \n",
    "file = \"/home/zchen/encyclopedia-text-style-transfer/data/political_news/art_pairs.json\"\n",
    "art_pairs = get_art_pairs(cn_arts, tok_cn_arts, tw_arts, tok_tw_arts, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "joint-librarian",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3849\n"
     ]
    }
   ],
   "source": [
    "print(len(art_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "quarterly-capital",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def art2sents_str(art):\n",
    "    return art[\"headline\"] + '\\n' + art[\"text\"]\n",
    "    \n",
    "def get_s_t(s):\n",
    "    s_s, s_t = cc_t2s.convert(s), cc_s2t.convert(s)\n",
    "    s_s = [sent for sent in s_s.split('\\n') if len(sent) > 5]\n",
    "    s_t = [sent for sent in s_t.split('\\n') if len(sent) > 5]\n",
    "    assert len(s_s) == len(s_t), (len(s_s), len(s_t))\n",
    "    \n",
    "    zipped = list(zip(s_s, s_t))\n",
    "    zipped = list(set(zipped))\n",
    "    s_s, s_t = list(zip(*zipped))\n",
    "    assert len(s_s) == len(s_t), (len(s_s), len(s_t))\n",
    "    return s_s, s_t\n",
    "    \n",
    "def sents2ents(sentence_list):\n",
    "    word_sentence_list = ws(\n",
    "        sentence_list,\n",
    "        # sentence_segmentation = True, # To consider delimiters\n",
    "        # segment_delimiter_set = {\",\", \"。\", \":\", \"?\", \"!\", \";\"}), # This is the defualt set of delimiters\n",
    "        # recommend_dictionary = dictionary1, # words in this dictionary are encouraged\n",
    "        # coerce_dictionary = dictionary2, # words in this dictionary are forced\n",
    "    )\n",
    "    pos_sentence_list = pos(word_sentence_list)\n",
    "    entity_sentence_list = ner(word_sentence_list, pos_sentence_list)\n",
    "    \n",
    "    ent_sents = []\n",
    "    for sent, word_sent, pos_sent, ent_sent in zip(sentence_list, word_sentence_list, pos_sentence_list, entity_sentence_list):\n",
    "        ents = [word for word, pos in zip(word_sent, pos_sent) if re.match(r\"N[a-d]\", pos)]\n",
    "        # re.match() determines whether the pattern matches the beginning of the string,\n",
    "        # returns the matching object if it matches, and returns None if it does not match.\n",
    "        \n",
    "        ents += [ent[3] for ent in ent_sent]\n",
    "        ent_sents.append(set(ents))\n",
    "    return ent_sents\n",
    "    \n",
    "def get_score(src_ent_sent, targ_ent_sent):\n",
    "    intersection_len = len(src_ent_sent & targ_ent_sent)\n",
    "    if intersection_len == 0:\n",
    "        return 0\n",
    "    precision = intersection_len / len(targ_ent_sent)\n",
    "    recall = intersection_len / len(src_ent_sent)\n",
    "    targ_len = len(targ_ent_sent)\n",
    "    return (2*precision*recall) / (precision+recall)\n",
    "    \n",
    "def filter_sent(zipped, p):\n",
    "    \"\"\" filtering strategy, e.g., highest k sents or a threshold score p \"\"\"\n",
    "#     return zipped[:k]\n",
    "    \n",
    "    sents = []\n",
    "    for sent, score in zipped:\n",
    "        if score >= p:\n",
    "            sents.append((sent, score))\n",
    "        else:\n",
    "            break\n",
    "    return sents\n",
    "\n",
    "def get_pair(src_sent, targ_sents, src_ent_sent, targ_ent_sents):\n",
    "    scores = [get_score(src_ent_sent, targ_ent_sent) for targ_ent_sent in targ_ent_sents]\n",
    "    zipped = list(zip(targ_sents, scores))\n",
    "    zipped.sort(key=lambda x: x[1], reverse=True)\n",
    "    matched = filter_sent(zipped, p=0.3)\n",
    "    return (src_sent, matched)\n",
    "\n",
    "def get_pairs(src_sents_str, targ_sents_str):\n",
    "    src_sents_s, src_sents_t = get_s_t(src_sents_str)\n",
    "    targ_sents_s, targ_sents_t = get_s_t(targ_sents_str)\n",
    "    src_ent_sents, targ_ent_sents = sents2ents(src_sents_t), sents2ents(targ_sents_t)\n",
    "    return [get_pair(src_sent, targ_sents_s, src_ent_sent, targ_ent_sents) for src_sent, src_ent_sent in zip(src_sents_s, src_ent_sents)]\n",
    "\n",
    "def get_sent_pairs(art_pairs, targ_arts, file):\n",
    "    if os.path.exists(file):\n",
    "        return load_json(file)\n",
    "    else:\n",
    "        sent_pairs = []\n",
    "        \"\"\"\n",
    "        [\n",
    "            (src_sent_1, [(targ_sent_n, score), ...]),\n",
    "            ...\n",
    "            ]\n",
    "        \"\"\"\n",
    "\n",
    "        for i, (src_art, targ_art_ids) in enumerate(tqdm(art_pairs)):\n",
    "            src_sents_str = art2sents_str(src_art)\n",
    "            targ_sents_str = '\\n'.join([art2sents_str(targ_arts[i]) for i in targ_art_ids])\n",
    "            sent_pairs += get_pairs(src_sents_str, targ_sents_str)\n",
    "        save_json(file, sent_pairs)\n",
    "        return sent_pairs\n",
    "\n",
    "# 2hr\n",
    "file = \"/home/zchen/encyclopedia-text-style-transfer/data/political_news/sent_pairs.json\"\n",
    "sent_pairs = get_sent_pairs(art_pairs, tw_arts, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "pressed-hopkins",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31744 8819 22782 2.5832860868579206\n",
      "[['俄乌代表在谈判开始前握手', [['首轮停战谈判无果！ 乌俄第二回合会谈2日举行', 0.4], ['乌俄谈判第一回合结束！下次会谈选在波兰、白俄交界', 0.3333333333333333], ['乌俄第三轮谈判今晚10点开始 双方外长周四将会面', 0.30769230769230765]]], ['当地时间3月3日，俄罗斯与乌克兰的第二轮谈判正式开始。据俄罗斯卫星通讯社消息，乌克兰总统办公室主任顾问波多利亚克表示，列入与俄谈判议程的有停火、休战、开放疏散人员的人道主义走廊。俄罗斯代表团和乌克兰代表团的成员在会谈时相互握手。', [['《CNN》指出，稍早网路上一段影片显示，乌俄双方代表团已碰面，在坐下会谈前先相互握手。乌克兰代表团成员之一、乌克兰总统办公室主任顾问波多利亚克在推特分享一张乌俄代表已就定位准备谈判的照片指出，「我们已开始与俄罗斯代表会谈，此次主要议程有三，『立即停火』、『停战撤军』、『设人道走廊将无辜平民从被毁或不断遭受砲火的城镇救出』。」', 0.4827586206896552], ['乌克兰总统泽伦斯基（Volodymyr Zelenskiy）的助理在台湾时间3日晚间透露，乌克兰代表团已搭乘直升机赴与俄谈判地点。稍早，乌克兰代表团成员之一的波多利亚克（Mykhailo Podoliak）在推特PO出照片，显示乌俄第二轮谈判已经展开！', 0.4230769230769231], ['乌克兰总统顾问波多利亚克（Mikhailo Podolyak）今日稍早在推特上表示，「与俄罗斯联邦的第三轮谈判，将在基辅时间16点开始。代表人员没有变动。」不过，波多利亚克没有透露谈判地点。', 0.35555555555555557], ['乌克兰与俄罗斯在2月28进行首轮停战谈判无果，俄官媒昨（3/1）声称2日会举行第2轮会谈，克里姆林宫也于周三表示希望乌克兰代表团能依约前去谈判，稍早乌克兰总统助理证实，双方将于当地时间2日开展第二回合谈判，但确切时间没透露。', 0.35294117647058826], ['乌俄首轮谈判约在2月28日当地时间下午1时（台湾时间晚间7时）在白俄罗斯邻近乌克兰边境的戈梅利州（Gomel region）展开，乌克兰总统办公室主任顾问波多利亚克（Mykhailo Podoliak）表示，乌方在会谈中要求撤出所有俄罗斯军队，包括从2014年占领的克里米亚和顿巴斯地区撤出；俄国谈判条件为乌克兰回归中立国家，另承认俄国对克里米亚的主权。', 0.33333333333333337], ['据CNN报导，乌克兰总统泽伦斯基（Volodymyr Zelenskiy）助理稍早证实，与俄国的第2轮谈判定于今天举行，代表团将由第一轮谈判的成员组成，包括国防部长列兹尼科夫（Oleksii Reznikov）、乌克兰总统办公室主任顾问波多利亚克（Mykhailo Podoliak）及乌克兰外交部副部长托奇茨基（Mykola Tochytsky）。', 0.32727272727272727], ['乌俄第2轮谈判开始！乌克兰总统顾问曝议程3重点', 0.30769230769230765], ['综合外媒报导，乌俄谈判约在28日当地时间下午1时（台湾时间晚间7时）在白俄罗斯邻近乌克兰边境的戈梅利州（Gomel region）展开，乌国谈判代表有国防部长列兹尼科夫、总统办公室主任顾问波多利亚克（Mykhailo Podoliak）及外交部副部长托奇茨基（Mykola Tochytsky）。', 0.30000000000000004]]], ['当地时间3月3日，俄罗斯与乌克兰的第二轮谈判正式开始。据俄新社消息，乌克兰外交部负责人表示，基辅不会在领土完整问题的上作出让步。', [['乌克兰与俄罗斯在2月28进行首轮停战谈判，由于暂无结果，双方代表团各自返回基辅和莫斯科进行进一步磋商，并计划继续进行下一轮谈判。俄媒报导，乌俄代表团第二轮会谈定于3月2日举行。', 0.34285714285714286], ['中国外交部也发布公告指出，中国外交部长王毅今天与俄罗斯外交部长拉夫罗夫通话，拉夫罗夫说明了乌克兰局势与俄方立场，王毅则说，「中方一贯尊重各国的主权和领土完整」，但他认为，乌克兰问题有其复杂而特殊的历史脉络，中国「理解俄方在安全问题上的『合理关切』」。', 0.3157894736842105]]], ['乌克兰称拒绝就领土问题让步', [['外媒记者质疑，中国常说要尊重国家主权和领土完整，却在乌克兰问题上态度暧昧，是否双重标准。', 0.39999999999999997], ['报导说，北京第三个答不出的问题是「中国在乌克兰问题上有不同标准？」', 0.36363636363636365]]], ['俄乌第二轮谈判开始', [['俄乌第二轮谈判改地点 《央视》：可能明天登场', 0.6666666666666666], ['首轮停战谈判无果！ 乌俄第二回合会谈2日举行', 0.5454545454545454], ['乌俄第2轮谈判开始！乌克兰总统顾问曝议程3重点', 0.37499999999999994]]], ['据白俄罗斯国家通讯社消息，当地时间3月3日，俄罗斯与乌克兰的第二轮谈判，在白俄罗斯别洛韦日森林正式开始。本轮谈判一再被推迟，俄方代表团率先抵达，乌方一度拒绝将谈判地点定在别洛韦日森林，不过还是在稍早前乘直升机抵达。', [['乌克兰总统泽伦斯基（Volodymyr Zelenskiy）的助理在台湾时间3日晚间透露，乌克兰代表团已搭乘直升机赴与俄谈判地点。稍早，乌克兰代表团成员之一的波多利亚克（Mykhailo Podoliak）在推特PO出照片，显示乌俄第二轮谈判已经展开！', 0.3829787234042554], ['这次会谈地点据称是选在白俄罗斯布列斯特州（Brest）的比亚沃维耶扎原始森林（Belovezhskaya）保护区（与波兰接壤），确切地点和首轮会谈一样，考虑到与会成员安全，并未向外界完整透露。而乌克兰代表团在台湾时间3日晚间搭直升机赴会，各界都相当关注。', 0.3555555555555555], ['据《俄罗斯卫星网》报导，1名了解谈判进程的消息人士透露，乌克兰代表团已在白俄罗斯境内，正在前往谈判地点，预计与俄方谈判代表的会议将于今早开始，谈判地点在白俄罗斯东南，与乌克兰、俄罗斯相连的戈梅利州（Gomel Region），在谈判开始前，乌国总统泽伦斯基与白俄罗斯总统卢卡申科（Alexander Lukashenko）通电。', 0.31999999999999995], ['乌克兰与俄罗斯在2月28进行首轮停战谈判无果，俄官媒昨（3/1）声称2日会举行第2轮会谈，克里姆林宫也于周三表示希望乌克兰代表团能依约前去谈判，稍早乌克兰总统助理证实，双方将于当地时间2日开展第二回合谈判，但确切时间没透露。', 0.30434782608695654], ['乌克兰与俄罗斯在2月28进行首轮停战谈判，由于暂无结果，双方代表团各自返回基辅和莫斯科进行进一步磋商，并计划继续进行下一轮谈判。俄媒报导，乌俄代表团第二轮会谈定于3月2日举行。', 0.3]]], ['综合消息：乌克兰与俄罗斯会谈代表团成员、乌克兰执政的人民公仆党议会派领袖大卫·阿拉卡米亚3日在社交平台发文称，乌方计划在与俄罗斯进行新一轮谈判的过程中，至少就建立人道主义走廊达成一致。', []], ['俄乌双方代表团2月28日在白俄罗斯戈梅利州举行首轮谈判。谈判持续约5小时，双方分歧较大，乌总统泽连斯基称，会谈没有取得预期想达到的结果。但双方代表团在首轮谈判后一致表示，同意继续谈判。', [['俄乌谈判17:00开始 乌克兰代表团「阶级非常高」', 0.36363636363636365], ['俄罗斯总统助理、俄谈判代表团团长梅金斯基表示，预计乌代表团将在1-2小时内抵达谈判地，双方会谈预计将于格林威治标准时间28日上午9点开始，梅金斯基表示，他无权曝光乌克兰谈判代表身分，仅透露乌克兰所派出的官员阶级「非常高」。', 0.3157894736842105]]], ['第二轮俄乌谈判地点分歧大 双方将讨论建立人道主义走廊', [['俄乌第二轮谈判改地点 《央视》：可能明天登场', 0.6666666666666666], ['首轮停战谈判无果！ 乌俄第二回合会谈2日举行', 0.42857142857142855], ['俄乌谈判17:00开始 乌克兰代表团「阶级非常高」', 0.375]]], ['俄新社3日援引梅金斯基的话称，第二轮俄乌谈判地点可能更改至白俄罗斯布列斯特州，但双方还没有最终做出决定。', [['俄乌第二轮谈判改地点 《央视》：可能明天登场', 0.5263157894736842], ['首轮停战谈判无果！ 乌俄第二回合会谈2日举行', 0.3333333333333333], ['俄乌谈判17:00开始 乌克兰代表团「阶级非常高」', 0.3]]]]\n"
     ]
    }
   ],
   "source": [
    "n_src = sum([len(targs) > 0 for src, targs in sent_pairs])\n",
    "n_pairs = sum([len(targs) for src, targs in sent_pairs])\n",
    "avg_pairs = n_pairs / n_src\n",
    "print(len(sent_pairs), n_src, n_pairs, avg_pairs)\n",
    "print(sent_pairs[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "stuffed-girlfriend",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(pairs, maxlen=254, n_test=1000, seed=\"TST\"):\n",
    "    # remove long sentences\n",
    "    _pairs = pairs\n",
    "    pairs = []\n",
    "    for src, targs in _pairs:\n",
    "        if len(src) <= maxlen:\n",
    "            targs = [(targ, score) for targ, score in targs if len(targ) <= maxlen]\n",
    "            if targs:\n",
    "                pairs.append((src, targs))\n",
    "    \n",
    "    random.seed(seed)\n",
    "    random.shuffle(pairs)\n",
    "    random.seed()\n",
    "            \n",
    "    sep1 = -2 * n_test\n",
    "    sep2 = -n_test\n",
    "    return pairs[:sep1], pairs[sep1:sep2], pairs[sep2:]\n",
    "\n",
    "def pairs2datasets(pairs):\n",
    "    train_pairs, valid_pairs, test_pairs = split_data(pairs)\n",
    "    \n",
    "    train_ds = []\n",
    "    for src, targs in train_pairs:\n",
    "        train_ds += [(src, targ) for targ, score in targs]\n",
    "    \n",
    "    valid_ds = [(src, targs[0][0]) for src, targs in valid_pairs if targs]\n",
    "    test_ds = [(src, targs[0][0]) for src, targs in test_pairs if targs]\n",
    "    return train_ds, valid_ds, test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "several-dialogue",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17384\n",
      "[('中国国务委员兼外长王毅29日同欧盟外交与安全政策高级代表博雷利举行视频会见。王毅强调，处理复杂的安全问题，不应采取非敌即友、非黑即白的简单化做法。各国都有权独立自主地决定自己的对外政策。事实证明，冷战思维、阵营对抗的老路在欧洲已经行不通了，选边站队、分裂世界的做法更不可取。极限制裁只会导致互相伤害，使形势更加复杂，矛盾更加激化。让非当事方的国家和人民为冲突埋单，既不公正，也不合法。中方愿同各方一道，照顾各方正当合理关切，朝着争取俄乌冲突尽快解决、欧洲尽快恢复和平的大方向做出努力。', '中国与俄罗斯同样反对北约扩张，但并不等同于支持俄乌开战。中方多次在公开声明中促进各方缓和乌克兰紧张局势，支持俄乌开启谈判对话。欧盟外交与安全政策高级代表波瑞尔（Josep Borrell）日前表示，只有中国能充当俄乌调停人，中国驻欧盟使团当地时间5日回应，中方鼓励俄乌直接谈判。中国驻欧盟使团的回应，维持了不介入姿态。'), ('东西问·中外对话 | 斯蒂芬·佩里：为什么说美国“错过”了中国的崛起？', '与此同时，中国敦促美国尊重并解决俄罗斯对于安全保证的要求。'), ('3月4日，十三届全国人大五次会议新闻发布会在人民大会堂举行，大会发言人张业遂说——', '吴谦今以全国人大五次会议解放军和武警部队代表团新闻发言人身分，讲解军费安排，他称，中国国防支出预算每年都纳入政府预算草案，并由人民代表大会审查后依法使用，也对外公开预算总额。'), ('俄媒报道称，乌克兰总统办公室顾问证实，乌方代表团尚未抵达谈判地点，并敦促等待对话的真正开始。', '乌俄第2轮谈判开始！乌克兰总统顾问曝议程3重点'), ('俄媒报道称，乌克兰总统办公室顾问证实，乌方代表团尚未抵达谈判地点，并敦促等待对话的真正开始。', '乌克兰总统泽伦斯基（Volodymyr Zelenskiy）的助理在台湾时间3日晚间透露，乌克兰代表团已搭乘直升机赴与俄谈判地点。稍早，乌克兰代表团成员之一的波多利亚克（Mykhailo Podoliak）在推特PO出照片，显示乌俄第二轮谈判已经展开！'), ('俄媒报道称，乌克兰总统办公室顾问证实，乌方代表团尚未抵达谈判地点，并敦促等待对话的真正开始。', '地点曝光！ 乌克兰证实2日与俄罗斯续谈 谈判代表与首轮相同'), ('俄媒报道称，乌克兰总统办公室顾问证实，乌方代表团尚未抵达谈判地点，并敦促等待对话的真正开始。', '据CNN报导，乌克兰总统泽伦斯基（Volodymyr Zelenskiy）助理稍早证实，与俄国的第2轮谈判定于今天举行，代表团将由第一轮谈判的成员组成，包括国防部长列兹尼科夫（Oleksii Reznikov）、乌克兰总统办公室主任顾问波多利亚克（Mykhailo Podoliak）及乌克兰外交部副部长托奇茨基（Mykola Tochytsky）。'), ('俄媒报道称，乌克兰总统办公室顾问证实，乌方代表团尚未抵达谈判地点，并敦促等待对话的真正开始。', '乌俄将第2轮谈判！  传普廷准备扶植前乌克兰逃亡总统... （不断更新）'), ('【环球网快讯】据法新社刚刚消息，俄罗斯方面称其再次向乌克兰境内发射高超音速导弹。', '俄罗斯国防部宣称，仓库内放置了飞弹及航空弹药（Aviation Ammunition）；官媒俄新社（RIA）则强调，这是对乌克兰执行的「特殊军事行动」』中，首次使用匕首高超音速飞弹。'), ('巴西累计确诊病例超2952万例 圣保罗州放宽“强制口罩令”', '美国日增病例较高峰骤降90％ 多州解除口罩令')]\n",
      "\n",
      "1000\n",
      "[('韩国共同民主党党首宋永吉在大选造势活动中遇袭 头部受伤送医', '韩国总统大选造势 民众热情不畏疫情'), ('自2020年初新冠疫情大流行开始以来，至第一个100万死亡人数用了7个月时间，四个月后又有100万人死亡，此后每三个月就有100万人死亡，直到2021年10月底，死亡人数达到500万人。现在这个数字已经逼近600万。', '2020年初疫情开始流行后，经过7个月全世界死亡人数达到100万。4个月后，又有100万人死亡，以后每3个月就有100万人死亡，到2021年10月底死亡总数达到500万人。现在死亡人数已逼近600万，比柏林加上布鲁塞尔的人口总数，或者整个美国马里兰州（Maryland）的人口总数还要多。'), ('自俄军在乌克兰开展军事行动以来，乌克兰方面曾多次要求美国和北约在乌克兰设立禁飞区，但均遭到拒绝。', '俄罗斯总统普廷自上月24日起大举侵略乌克兰，引发多国制裁，乌克兰总统泽伦斯基先前也向北大西洋公约组织（NATO）要求，希望在乌克兰上空设立禁飞区，以阻止俄军的空袭行动，不过北约拒绝该项要求，强调不希望让冲突持续扩大，拒绝直接介入与俄罗斯的军事冲突。'), ('【环球网报道】乌克兰总统泽连斯基呼吁增加对乌军事援助后，又喊话其他国家的外交使团返回基辅。', '第二大城遭无差别轰炸 乌总统：俄正施行国家恐怖主义'), ('樊胜根：在全球层面，很重要的一点是我们要呼吁各国不要采取贸易出口限制的方法，保持全世界粮食贸易的畅通，让粮食能够运出去，使各国粮食能够互通有无。当前，全世界粮食贸易供需基本平衡，但这种平衡一旦被战争打破，对世界粮食市场的冲击是很大的。近段时间以来，多国限制出口、相互制裁，就引发了市场担忧。', '据悉，联合国秘书长古特瑞斯（Antonio Guterres）15日就曾警告，全球各国必须迅速采取行动，以防全球粮食体系崩溃，导致「饥荒四起」。古特瑞斯说：「这场战争所带来的冲击远不止于乌克兰，同时也重击了世界上最脆弱的人民和国家。」'), ('当地时间3月8日晚，俄罗斯国防部发布了最新战况信息，从特别军事行动开始以来一共瘫痪了2581个乌克兰军事目标，其中包括90个指挥所和通讯点，123套S-300、山毛榉M1和黄蜂防空导弹系统以及81个雷达站。', '《俄罗斯卫星通讯社》报导，俄罗斯国防部新闻发言人8日对外称，自2月24日开始进行「特别军事行动」以来，共有2482处乌克兰军事基础目标被摧毁，其中包括87个指挥所和通讯点、124套S-300、山毛榉和黄蜂防空飞弹系统以及79个雷达站。'), ('据俄罗斯卫星通讯社报道，当地时间20日，俄罗斯外交部发言人扎哈罗娃在新闻发布会上表示，俄乌谈判仍在进行。', '传俄乌和谈已草拟15条件 克宫发言人：假新闻！'), ('此间，乌总统泽连斯基透露了几个重要信息。其中一个是，他认为乌方抵抗将长期化，准备“与俄对战十年”；另一个，则与美国有莫大关系。俄乌冲突背后的“剧本”，或许还很长。', '●乌克兰总统与俄关系'), ('白宫还表示，美国总统拜登最近一次4日新冠检测结果呈阴性。目前，拜登没有与确诊新冠者有密切接触。', '莎琪提到，她与拜登周一在维持社交距离的情况下开过两场会，「依照CDC标准，总统并不算是密切接触者，他的PCR检测结果也为阴性。」'), ('综合消息：俄罗斯总统普京12日表示，乌方背离了在伊斯坦布尔谈判的成果，使局面陷入了死胡同。乌方对此予以否认。波兰和波罗的海三国总统13日访问乌克兰，德国总统因“不受乌方欢迎”取消基辅行程。此外，世界贸易组织12日发布的全球贸易年度预测报告认为，俄乌冲突危及本就脆弱的全球贸易复苏。', '俄罗斯总统普廷无视全球谴责和多国制裁，2月24日迳行宣布对乌克兰采取特殊军事作战，开启战争。本报根据路透、法新社、彭博、CNN、BBC等外电，整理了截至台湾时间3月13日最新情势发展，让读者快速掌握俄乌冲突最新进展。')]\n",
      "\n",
      "1000\n",
      "[('新的旅客申报系统要求旅客在前往新西兰前上传最近的旅行记录和与疫情相关的健康信息，如疫苗接种证明、出发前检测结果等。', '据报导，所有旅客在出发前皆须完成疫苗接种，并提供筛检阴性证明，在抵达纽西兰时及入境后第6天也需接受检测。'), ('韩政府再次延长全球旅行安全特别预警 为期一个月', '南韩单周暴增逾210万例 延长全球旅游预警至4月中'), ('除了难以预测，此次韩国大选被韩媒形容为“不受欢迎的总统选举”。', '韩国总统大选造势 民众热情不畏疫情'), ('为防乌克兰难民涌入 捷克进入紧急状态', '应对大量乌克兰难民涌入 捷克明起进入紧急状态'), ('本报记者对话三位国际问题专家，起底美国如何利用俄乌冲突大肆劫掠、为己渔利，并分析美国此举将带来哪些损人害己的严重后果。', '俄罗斯对乌克兰肆无忌惮发动军事攻击，代表国际政治新秩序的第一场重大冲突。美俄中三个大国互相竞争，美国的主宰地位备受威胁。'), ('此前在22日，美军未事先通报就在冲绳县名护湾实施了直升机悬挂训练，致使冲绳县当地的批评意见高涨。冲绳县出于安全考虑，要求日本政府让美军不要再次实施该训练。名护市议会28日全会一致通过了要求禁止训练的决议和意见书。', '驻日美军训练行动时常引起当地民众不满，驻日美军在22日在冲绳县名护湾实施直升机悬挂训练未事先通报，冲绳县政府要求日本政府让美军不要再次实施此训练。不过外务大臣林芳正29日在记者会中表示，美军军机在美军基地外训练时，只要不进行实弹射击就允许。'), ('报道称，朴槿惠目前在三星首尔医院住院。据韩联社报道，朴槿惠很可能下周出院，最晚也在本月内出院并入住私邸，但具体时间尚未确定。朴槿惠曾表示在出院之际向韩国民众释放信息，届时是否提到韩国候任总统尹锡悦引起关注。', '南韩前总统朴槿惠在首尔时间24日上午8时32分从三星首尔医院出院，向外界表示，已经康复许多，感谢医务人员的精心治疗和照顾。这是朴槿惠获得特赦后首次露面。'), ('梅德韦杰夫称对俄无规则经济战将摧毁世界经济秩序', '拜登：俄应被逐出G20 中清楚与西方经济联系更胜俄'), ('俄总统新闻秘书：在乌特别军事行动目标将全面实现', '＊俄罗斯承诺减少军事行动，美国总统拜登（Joe Biden）表示，在看到实际行动之前，他不会相信俄国声明的每一个字，「我们拭目以待」。'), ('据韩媒报道，5日，由于韩国东南部的山火持续蔓延，韩国消防厅首次面向全国发布最高级别火险预警。', '南韩东南部4日发生森林大火，火势现持续蔓延，当局今日向该国全境发布最高等级火险预警，为南韩史上首见。')]\n"
     ]
    }
   ],
   "source": [
    "train_ds, valid_ds, test_ds = pairs2datasets(sent_pairs)\n",
    "print(len(train_ds))\n",
    "print(train_ds[:10])\n",
    "print()\n",
    "print(len(valid_ds))\n",
    "print(valid_ds[:10])\n",
    "print()\n",
    "print(len(test_ds))\n",
    "print(test_ds[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ethical-allergy",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dataset(dataset, src_file, targ_file):\n",
    "    src, targ = zip(*dataset)\n",
    "    save_corpus(src, src_file)\n",
    "    save_corpus(targ, targ_file)\n",
    "    \n",
    "def save_corpus(sent_list, file):\n",
    "    corpus = '\\n'.join(sent_list) + '\\n'\n",
    "    with open(file, 'w', encoding=\"utf-8\") as f:\n",
    "        f.write(corpus)\n",
    "    \n",
    "for dataset, split in [(train_ds, \"train\"), (valid_ds, \"valid\"), (test_ds, \"test\")]:\n",
    "    src_file = f\"/home/zchen/XLM_ETST/data/cn-tw_1k/txt/cn-tw.cn.{split}_raw\"\n",
    "    targ_file = f\"/home/zchen/XLM_ETST/data/cn-tw_1k/txt/cn-tw.tw.{split}_raw\"\n",
    "    save_dataset(dataset, src_file, targ_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "psychological-marathon",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sentence_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2468837/2073699464.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"'{sentence}'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sentence_list' is not defined"
     ]
    }
   ],
   "source": [
    "def print_word_pos_sentence(word_sentence, pos_sentence):\n",
    "    assert len(word_sentence) == len(pos_sentence)\n",
    "    for word, pos in zip(word_sentence, pos_sentence):\n",
    "        print(f\"{word}({pos})\", end=\"\\u3000\")\n",
    "    print()\n",
    "    return\n",
    "    \n",
    "for i, sentence in enumerate(sentence_list):\n",
    "    print()\n",
    "    print(f\"'{sentence}'\")\n",
    "    print_word_pos_sentence(word_sentence_list[i],  pos_sentence_list[i])\n",
    "    for entity in sorted(entity_sentence_list[i]):\n",
    "        print(entity)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "text_style_transfer",
   "language": "python",
   "name": "text_style_transfer"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
